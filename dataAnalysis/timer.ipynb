{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: plotly in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (5.24.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from pandas) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from plotly) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/s3/gx423dyd2hg9sfb092jr70f00000gn/T/ipykernel_35461/3843771874.py\", line 5, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/numexpr/__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/s3/gx423dyd2hg9sfb092jr70f00000gn/T/ipykernel_35461/3843771874.py\", line 5, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/arrays/masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/core/nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/bottleneck/__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas plotly\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PROLIFIC_PID         ResponseId   Order Technique  Time  \\\n",
      "0  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  second   analogy   NaN   \n",
      "1  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5   first  baseline   NaN   \n",
      "2  62db2644ab0a3a353c0dcb54  R_2HiGIWFCHg1Nmox   first   analogy   NaN   \n",
      "3  62db2644ab0a3a353c0dcb54  R_2HiGIWFCHg1Nmox  second  baseline   NaN   \n",
      "4  629f6b8c65fcae219e245284  R_2NDQ5emeod1xphg   first   analogy   NaN   \n",
      "\n",
      "   PerformanceScore  DescriptionScore  ChartDifficulties  VARK sketchscore  \n",
      "0               NaN               NaN                NaN   NaN        None  \n",
      "1               NaN               NaN                NaN   NaN        None  \n",
      "2               NaN               NaN                NaN   NaN        None  \n",
      "3               NaN               NaN                NaN   NaN        None  \n",
      "4               NaN               NaN                NaN   NaN        None  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data assuming '41.csv' is your filename\n",
    "data = pd.read_csv('temp.csv')\n",
    "\n",
    "# Step 1: Drop the first row (repeatedly dropping first index), maintaining your instructions\n",
    "data = data.drop(index=0).reset_index(drop=True)\n",
    "data = data.drop(index=0).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Create a list to hold all the rows that will later form the new DataFrame\n",
    "rows = []\n",
    "\n",
    "# Step 3: Iterate over each participant's data to create the new rows\n",
    "for index, row in data.iterrows():\n",
    "    pid = row['PROLIFIC_PID']\n",
    "    response_id = row['ResponseId']\n",
    "    group = row.get('Group')  # Assuming 'Group' is a column in your data for logic\n",
    "\n",
    "    # Create a row for 'analogy' with initialized empty 'sketchscore'\n",
    "    analogy_row = {\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'Technique': 'analogy',\n",
    "        'sketchscore': None\n",
    "    }\n",
    "\n",
    "    # Create a row for 'baseline' with initialized empty 'sketchscore'\n",
    "    baseline_row = {\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'Technique': 'baseline',\n",
    "        'sketchscore': None\n",
    "    }\n",
    "\n",
    "    # Assign 'Order' based on 'Group'\n",
    "    if group == '1':\n",
    "        analogy_row['Order'] = 'first'\n",
    "        baseline_row['Order'] = 'second'\n",
    "    elif group == '2':\n",
    "        analogy_row['Order'] = 'second'\n",
    "        baseline_row['Order'] = 'first'\n",
    "\n",
    "    # Add the created rows to the list\n",
    "    rows.append(analogy_row)\n",
    "    rows.append(baseline_row)\n",
    "\n",
    "# Step 4: Create a new DataFrame from the list of rows\n",
    "new_data = pd.DataFrame(rows, columns=['PROLIFIC_PID', 'ResponseId', 'Order', 'Technique', 'Time', 'PerformanceScore', 'DescriptionScore', 'ChartDifficulties', 'VARK', 'sketchscore'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(new_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PROLIFIC_PID         ResponseId   Order Technique  Time  \\\n",
      "0  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  second   analogy   NaN   \n",
      "1  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5   first  baseline   NaN   \n",
      "2  62db2644ab0a3a353c0dcb54  R_2HiGIWFCHg1Nmox   first   analogy   NaN   \n",
      "3  62db2644ab0a3a353c0dcb54  R_2HiGIWFCHg1Nmox  second  baseline   NaN   \n",
      "4  629f6b8c65fcae219e245284  R_2NDQ5emeod1xphg   first   analogy   NaN   \n",
      "\n",
      "   PerformanceScore  DescriptionScore  ChartDifficulties VARK sketchscore  \n",
      "0               NaN               NaN                NaN    K        None  \n",
      "1               NaN               NaN                NaN    K        None  \n",
      "2               NaN               NaN                NaN    V        None  \n",
      "3               NaN               NaN                NaN    V        None  \n",
      "4               NaN               NaN                NaN    A        None  \n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "# Step 3: Iterate over each participant's data to create the new rows\n",
    "for index, row in data.iterrows():\n",
    "    pid = row['PROLIFIC_PID']\n",
    "    response_id = row['ResponseId']\n",
    "    group = row.get('Group')  # Assuming 'Group' is a column in your data for logic\n",
    "\n",
    "    # Calculate dominant VARK modality\n",
    "    vark_types = ['V', 'A', 'R', 'K']\n",
    "    vark_counts = {v: 0 for v in vark_types}\n",
    "    for j in range(1, 17):\n",
    "        vark_col = f'VARK {j}'\n",
    "        if vark_col in row and pd.notna(row[vark_col]):\n",
    "            vark_values = str(row[vark_col]).split(',')\n",
    "            for v in vark_values:\n",
    "                v = v.strip()\n",
    "                if v in vark_types:\n",
    "                    vark_counts[v] += 1\n",
    "    max_count = max(vark_counts.values())\n",
    "    dominant_varks = [v for v, count in vark_counts.items() if count == max_count]\n",
    "    dominant_vark = ''\n",
    "    for v in vark_types:\n",
    "        if v in dominant_varks:\n",
    "            dominant_vark = v\n",
    "            break\n",
    "\n",
    "    # Create a row for 'analogy'\n",
    "    analogy_row = {\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'Technique': 'analogy',\n",
    "        'sketchscore': None,\n",
    "        'VARK': dominant_vark\n",
    "    }\n",
    "\n",
    "    # Create a row for 'baseline'\n",
    "    baseline_row = {\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'Technique': 'baseline',\n",
    "        'sketchscore': None,\n",
    "        'VARK': dominant_vark\n",
    "    }\n",
    "\n",
    "    # Assign 'Order' based on 'Group'\n",
    "    if group == '1':\n",
    "        analogy_row['Order'] = 'first'\n",
    "        baseline_row['Order'] = 'second'\n",
    "    elif group == '2':\n",
    "        analogy_row['Order'] = 'second'\n",
    "        baseline_row['Order'] = 'first'\n",
    "\n",
    "    # Add the created rows to the list\n",
    "    rows.append(analogy_row)\n",
    "    rows.append(baseline_row)\n",
    "\n",
    "# Step 4: Create a new DataFrame from the list of rows\n",
    "new_data = pd.DataFrame(rows, columns=['PROLIFIC_PID', 'ResponseId', 'Order', 'Technique', 'Time', 'PerformanceScore', 'DescriptionScore', 'ChartDifficulties', 'VARK', 'sketchscore'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(new_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '6713a8d7b21cb26dbea856bb', 'ResponseId': 'R_23mJW9D7hbbGMW5', 'ChartType': 'BarChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '62db2644ab0a3a353c0dcb54', 'ResponseId': 'R_2HiGIWFCHg1Nmox', 'ChartType': 'ButterflyChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '629f6b8c65fcae219e245284', 'ResponseId': 'R_2NDQ5emeod1xphg', 'ChartType': 'BarChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '66c4a32221f616ebf48ab21d', 'ResponseId': 'R_8cejxSsSh86Lfd7', 'ChartType': 'ButterflyChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '6731fd49cb5d1b254feacf29', 'ResponseId': 'R_2suArSWHDNKb4tH', 'ChartType': 'ButterflyChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '61267b828ead584bcf092e35', 'ResponseId': 'R_2DtOcX1JcVzppo6', 'ChartType': 'Sunburst'}\n",
      "               PROLIFIC_PID         ResponseId ChartType           TimerType  \\\n",
      "0  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  BarChart  Timer1_First Click   \n",
      "1  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  BarChart  Timer1_First Click   \n",
      "2  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  BarChart   Timer1_Last Click   \n",
      "3  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  BarChart   Timer1_Last Click   \n",
      "4  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  BarChart  Timer2_First Click   \n",
      "\n",
      "   Set   Value  \n",
      "0    1   7.251  \n",
      "1    2   5.113  \n",
      "2    1  66.807  \n",
      "3    2  62.844  \n",
      "4    1  27.807  \n",
      "Total rows: 190\n"
     ]
    }
   ],
   "source": [
    "key_columns = ['PROLIFIC_PID', 'ResponseId', 'ChartType']\n",
    "timer_columns_suffix = ['First Click', 'Last Click']\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Iterate over each participant's original data row\n",
    "for index, row in data.iterrows():\n",
    "    # Extract base information for each entry\n",
    "    base_info = {k: row[k] for k in key_columns}\n",
    "\n",
    "    # Collect all timer data by iterating column names\n",
    "    set_counter = 0\n",
    "    for timer_index in range(1, 9):  # Timer1 to Timer8\n",
    "        for click_type in timer_columns_suffix:\n",
    "            # Pattern to search for multiple occurrences\n",
    "            timer_pattern = f'Timer{timer_index}_{click_type}'\n",
    "            occurrences = (col for col in data.columns if timer_pattern in col)\n",
    "\n",
    "            # For each occurrence in columns, fetch the value\n",
    "            for timer_col in occurrences:\n",
    "                if pd.notna(row[timer_col]):\n",
    "                    new_row = base_info.copy()\n",
    "                    new_row['TimerType'] = timer_pattern\n",
    "                    new_row['Set'] = set_counter % 2 + 1\n",
    "                    new_row['Value'] = row[timer_col]\n",
    "                    rows.append(new_row)\n",
    "                    set_counter += 1\n",
    "\n",
    "    # Ensure only two sets are recorded per aspect\n",
    "    sets_to_ensure = 2 * len(timer_columns_suffix)\n",
    "    if set_counter / sets_to_ensure > 2:\n",
    "        print(f\"Warning: More than two set occurrences found for participant: {base_info}\")\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "timed_click_data = pd.DataFrame(rows)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(timed_click_data.head())\n",
    "print(\"Total rows:\", len(timed_click_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PROLIFIC_PID         ResponseId ChartType           TimerType  \\\n",
      "0  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  BarChart  Timer1_First Click   \n",
      "1  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  BarChart  Timer1_First Click   \n",
      "2  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  BarChart   Timer1_Last Click   \n",
      "3  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  BarChart   Timer1_Last Click   \n",
      "4  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  BarChart  Timer2_First Click   \n",
      "\n",
      "   Set   Value  \n",
      "0    1   7.251  \n",
      "1    2   5.113  \n",
      "2    1  66.807  \n",
      "3    2  62.844  \n",
      "4    1  27.807  \n"
     ]
    }
   ],
   "source": [
    "print(timed_click_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 PROLIFIC_PID         ResponseId ChartType  \\\n",
      "160  61267b828ead584bcf092e35  R_2DtOcX1JcVzppo6  Sunburst   \n",
      "162  61267b828ead584bcf092e35  R_2DtOcX1JcVzppo6  Sunburst   \n",
      "164  61267b828ead584bcf092e35  R_2DtOcX1JcVzppo6  Sunburst   \n",
      "166  61267b828ead584bcf092e35  R_2DtOcX1JcVzppo6  Sunburst   \n",
      "168  61267b828ead584bcf092e35  R_2DtOcX1JcVzppo6  Sunburst   \n",
      "\n",
      "              TimerType VisualizationTechnique    Value  \n",
      "160  Timer1_First Click                analogy   25.264  \n",
      "162   Timer1_Last Click                analogy  238.241  \n",
      "164  Timer2_First Click                analogy    0.205  \n",
      "166   Timer2_Last Click                analogy   88.686  \n",
      "168  Timer3_First Click                analogy   12.476  \n",
      "Total rows: 190\n"
     ]
    }
   ],
   "source": [
    "# Define key columns and timer column patterns\n",
    "key_columns = ['PROLIFIC_PID', 'ResponseId', 'ChartType']\n",
    "timer_columns_suffix = ['First Click', 'Last Click']\n",
    "\n",
    "# List to store transformed row data\n",
    "rows = []\n",
    "\n",
    "# Iterate over each participant's data to extract timer values\n",
    "for index, row in data.iterrows():\n",
    "    # Extract base information for each entry\n",
    "    base_info = {k: row[k] for k in key_columns}\n",
    "\n",
    "    # Counter to differentiate between sets\n",
    "    set_counter = 0\n",
    "    \n",
    "    for timer_index in range(1, 9):  # Timer1 to Timer8\n",
    "        for click_type in timer_columns_suffix:\n",
    "            timer_pattern = f'Timer{timer_index}_{click_type}'\n",
    "            occurrences = (col for col in data.columns if timer_pattern in col)\n",
    "\n",
    "            # Pull out each occurrence within timer column\n",
    "            for timer_col in occurrences:\n",
    "                if pd.notna(row[timer_col]):\n",
    "                    new_row = base_info.copy()\n",
    "                    new_row['TimerType'] = timer_pattern\n",
    "                    visualization_technique = \"analogy\" if set_counter % 2 == 0 else \"baseline\"\n",
    "                    new_row['VisualizationTechnique'] = visualization_technique\n",
    "                    new_row['Value'] = row[timer_col]\n",
    "                    rows.append(new_row)\n",
    "                    set_counter += 1\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "timed_click_data = pd.DataFrame(rows)\n",
    "\n",
    "# Sort the DataFrame by specified columns\n",
    "timed_click_data.sort_values(\n",
    "    by=['PROLIFIC_PID', 'ResponseId', 'ChartType', 'VisualizationTechnique', 'TimerType'],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(timed_click_data.head())\n",
    "print(\"Total rows:\", len(timed_click_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PROLIFIC_PID         ResponseId   Order Technique  Time_x  \\\n",
      "0  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  second   analogy     NaN   \n",
      "1  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5   first  baseline     NaN   \n",
      "2  62db2644ab0a3a353c0dcb54  R_2HiGIWFCHg1Nmox   first   analogy     NaN   \n",
      "3  62db2644ab0a3a353c0dcb54  R_2HiGIWFCHg1Nmox  second  baseline     NaN   \n",
      "4  629f6b8c65fcae219e245284  R_2NDQ5emeod1xphg   first   analogy     NaN   \n",
      "\n",
      "   PerformanceScore  DescriptionScore  ChartDifficulties VARK sketchscore  \\\n",
      "0               NaN               NaN                NaN    K        None   \n",
      "1               NaN               NaN                NaN    K        None   \n",
      "2               NaN               NaN                NaN    V        None   \n",
      "3               NaN               NaN                NaN    V        None   \n",
      "4               NaN               NaN                NaN    A        None   \n",
      "\n",
      "    Time_y  \n",
      "0  283.729  \n",
      "1  652.930  \n",
      "2  159.009  \n",
      "3  157.998  \n",
      "4  456.179  \n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Technique' column to match 'VisualizationTechnique'\n",
    "new_data['VisualizationTechnique'] = new_data['Technique']\n",
    "\n",
    "# Initialize list for storing calculated times\n",
    "timing_summations = []\n",
    "\n",
    "# Calculate time sums from 'timed_click_data'\n",
    "for (pid, response_id, visualization_technique), group in timed_click_data.groupby(['PROLIFIC_PID', 'ResponseId', 'VisualizationTechnique']):\n",
    "    total_time = 0\n",
    "    for timer_index in range(1, 9):\n",
    "        first_click_col = f'Timer{timer_index}_First Click'\n",
    "        last_click_col = f'Timer{timer_index}_Last Click'\n",
    "\n",
    "        # Extract the values for first and last clicks\n",
    "        first_clicks = group[group['TimerType'] == first_click_col]['Value']\n",
    "        last_clicks = group[group['TimerType'] == last_click_col]['Value']\n",
    "\n",
    "        # Calculate time differences\n",
    "        if not first_clicks.empty and not last_clicks.empty:\n",
    "            total_time += sum(float(lc) - float(fc) for lc, fc in zip(last_clicks, first_clicks))\n",
    "\n",
    "    # Append the result along with identifiers\n",
    "    timing_summations.append({\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'VisualizationTechnique': visualization_technique,  # Match renamed field\n",
    "        'Time': total_time\n",
    "    })\n",
    "\n",
    "# Convert timing_summations to a DataFrame\n",
    "time_df = pd.DataFrame(timing_summations)\n",
    "\n",
    "# Merge 'time_df' with 'new_data' based on matchable columns\n",
    "final_data = pd.merge(new_data, time_df, on=['PROLIFIC_PID', 'ResponseId', 'VisualizationTechnique'], how='left')\n",
    "\n",
    "# Drop the redundant 'VisualizationTechnique' column if needed\n",
    "final_data.drop(columns='VisualizationTechnique', inplace=True)\n",
    "\n",
    "# Display the final merged DataFrame\n",
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PROLIFIC_PID         ResponseId   Order Technique  Time  \\\n",
      "0  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5  second   analogy   NaN   \n",
      "1  6713a8d7b21cb26dbea856bb  R_23mJW9D7hbbGMW5   first  baseline   NaN   \n",
      "2  62db2644ab0a3a353c0dcb54  R_2HiGIWFCHg1Nmox   first   analogy   NaN   \n",
      "3  62db2644ab0a3a353c0dcb54  R_2HiGIWFCHg1Nmox  second  baseline   NaN   \n",
      "4  629f6b8c65fcae219e245284  R_2NDQ5emeod1xphg   first   analogy   NaN   \n",
      "\n",
      "   PerformanceScore  DescriptionScore  ChartDifficulties VARK sketchscore  \\\n",
      "0               NaN               NaN                NaN    K        None   \n",
      "1               NaN               NaN                NaN    K        None   \n",
      "2               NaN               NaN                NaN    V        None   \n",
      "3               NaN               NaN                NaN    V        None   \n",
      "4               NaN               NaN                NaN    A        None   \n",
      "\n",
      "  VisualizationTechnique       ChartType  TotalTime  \n",
      "0                analogy        BarChart    348.828  \n",
      "1               baseline        BarChart   4856.617  \n",
      "2                analogy  ButterflyChart    282.354  \n",
      "3               baseline  ButterflyChart    203.524  \n",
      "4                analogy        BarChart    517.525  \n"
     ]
    }
   ],
   "source": [
    "new_data['VisualizationTechnique'] = new_data['Technique']\n",
    "\n",
    "# Initialize a list to store timing summations\n",
    "timing_summations = []\n",
    "\n",
    "# Calculate time sums and ensure 'ChartType' is included\n",
    "for (pid, response_id, chart_type, technique), group in timed_click_data.groupby(['PROLIFIC_PID', 'ResponseId', 'ChartType', 'VisualizationTechnique']):\n",
    "    total_time = 0\n",
    "    for timer_index in range(1, 9):\n",
    "        first_click_col = f'Timer{timer_index}_First Click'\n",
    "        last_click_col = f'Timer{timer_index}_Last Click'\n",
    "\n",
    "        # Extract values and calculate sums\n",
    "        first_clicks = group[group['TimerType'] == first_click_col]['Value']\n",
    "        last_clicks = group[group['TimerType'] == last_click_col]['Value']\n",
    "        if not first_clicks.empty and not last_clicks.empty:\n",
    "            total_time += sum(float(lc) for lc, fc in zip(last_clicks, first_clicks))\n",
    "\n",
    "    # Append result with 'ChartType'\n",
    "    timing_summations.append({\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'ChartType': chart_type,\n",
    "        'VisualizationTechnique': technique,\n",
    "        'TotalTime': total_time\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from timing_summations\n",
    "time_df = pd.DataFrame(timing_summations)\n",
    "\n",
    "# Merge 'new_data' with 'time_df' on the necessary columns\n",
    "final_data = pd.merge(new_data, time_df, on=['PROLIFIC_PID', 'ResponseId', 'VisualizationTechnique'], how='left')\n",
    "\n",
    "# Display the final DataFrame with 'ChartType' included\n",
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.drop(columns=['Time'], inplace=True)\n",
    "\n",
    "# Display the final DataFrame to confirm changes\n",
    "final_data.to_csv('dataAnalysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
